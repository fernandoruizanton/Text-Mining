{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some terms in NLP** <br>\n",
    "    - Tokenizing - word tokenizer and Sentence tokenizer\n",
    "    - Lexicon - ex a Dictionary \n",
    "    - Corpora - body of text, ex journals , speeches, eng language\n",
    "    - Stop words - words which do not add any meaning in data analysis. ex 'a', 'and', 'the'\n",
    "    - Stemming - Get the root of the word. ex riding , ride , rode - gives root word ride\n",
    "    - Part of Speech Tagging\n",
    "    - Chunking - who/what is the sentence talking about ( subject ) . find words that affect that subject.Groups of noun and         words around that noun\n",
    "    - Similar to stemming , end result is a real word. Might end up with a different word ( maybe a synonym. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"Hello Mr. Nltk , I heard you are very good library so I'm gonna run some tests. Can you correctly identify sentences ? What about words ? And Phrases. Let's see how good you really are.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenize by sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Hello Mr. Nltk , I heard you are very good library so I'm gonna run some tests.\",\n",
       " 'Can you correctly identify sentences ?',\n",
       " 'What about words ?',\n",
       " 'And Phrases.',\n",
       " \"Let's see how good you really are.\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenize by words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Mr.', 'Nltk', ',', 'I', 'heard', 'you', 'are', 'very', 'good', 'library', 'so', 'I', \"'m\", 'gon', 'na', 'run', 'some', 'tests', '.', 'Can', 'you', 'correctly', 'identify', 'sentences', '?', 'What', 'about', 'words', '?', 'And', 'Phrases', '.', 'Let', \"'s\", 'see', 'how', 'good', 'you', 'really', 'are', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(example_text),sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'example', 'showing', 'stop', 'word', 'filteration']\n"
     ]
    }
   ],
   "source": [
    "example_sentence = \"This is an example showing off stop word filteration\"\n",
    "stop_words_list = set(stopwords.words('english'))\n",
    "tokenized_sentence = word_tokenize(example_sentence)\n",
    "filtered_sentence = [w for w in tokenized_sentence if not w in stop_words_list]\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sleep', 'is', 'the', 'present', 'tens', 'of', 'sleep', 'and', 'slept', 'is', 'the', 'past', 'tens', '.', 'python', 'python', 'pythonist', 'python']\n"
     ]
    }
   ],
   "source": [
    "text_to_stem = 'Sleeping is the present tense of sleep and slept is the past tense. Pythoning Pythoner Pythonist Pythoned'\n",
    "tokenized_text = word_tokenize(text_to_stem)\n",
    "ps = PorterStemmer()\n",
    "stemmed_text = [ps.stem(w) for w in tokenized_text] \n",
    "print(stemmed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatizing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "rock\n",
      "cactus\n",
      "goose\n",
      "good\n",
      "run\n",
      "best\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize('cats'))\n",
    "print(lemmatizer.lemmatize('rocks'))\n",
    "print(lemmatizer.lemmatize('cacti'))\n",
    "print(lemmatizer.lemmatize('geese'))\n",
    "print(lemmatizer.lemmatize('better',pos='a'))\n",
    "print(lemmatizer.lemmatize('run',pos='v'))\n",
    "print(lemmatizer.lemmatize('best',pos='a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
